{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model imports \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "#Data procesing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "#Visualization \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[[[171 173 191]\n",
      "  [170 170 189]\n",
      "  [173 171 186]\n",
      "  ..., \n",
      "  [185 179 199]\n",
      "  [181 179 200]\n",
      "  [178 179 201]]\n",
      "\n",
      " [[139 159 187]\n",
      "  [142 163 187]\n",
      "  [156 155 188]\n",
      "  ..., \n",
      "  [173 184 206]\n",
      "  [176 184 209]\n",
      "  [177 188 207]]\n",
      "\n",
      " [[159 166 197]\n",
      "  [160 165 196]\n",
      "  [160 164 198]\n",
      "  ..., \n",
      "  [179 186 210]\n",
      "  [183 189 211]\n",
      "  [186 190 206]]\n",
      "\n",
      " ..., \n",
      " [[ 41  74  94]\n",
      "  [ 59  73  87]\n",
      "  [ 61  73  95]\n",
      "  ..., \n",
      "  [ 71  40 103]\n",
      "  [ 71  37  85]\n",
      "  [ 63  41  93]]\n",
      "\n",
      " [[ 63  82 104]\n",
      "  [ 61  82 105]\n",
      "  [ 63  84 107]\n",
      "  ..., \n",
      "  [112  82 139]\n",
      "  [142 147 195]\n",
      "  [178 198 208]]\n",
      "\n",
      " [[ 71  88 110]\n",
      "  [ 68  88 111]\n",
      "  [ 69  88 111]\n",
      "  ..., \n",
      "  [ 93  90 125]\n",
      "  [113 132 138]\n",
      "  [143 184 177]]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[[[ 35  27  74]\n",
      "  [ 50  30  88]\n",
      "  [ 65  81 134]\n",
      "  ..., \n",
      "  [ 16   8  49]\n",
      "  [ 25   6  48]\n",
      "  [ 21   9  42]]\n",
      "\n",
      " [[ 50  57 100]\n",
      "  [ 33  30  90]\n",
      "  [ 58  43 113]\n",
      "  ..., \n",
      "  [ 23   7  48]\n",
      "  [ 22   9  45]\n",
      "  [ 20   8  45]]\n",
      "\n",
      " [[ 79  92 132]\n",
      "  [ 76  72 123]\n",
      "  [ 88  82 135]\n",
      "  ..., \n",
      "  [ 24   8  50]\n",
      "  [ 22   9  45]\n",
      "  [ 22   9  42]]\n",
      "\n",
      " ..., \n",
      " [[ 23  13  18]\n",
      "  [  8  11  17]\n",
      "  [ 15  12  18]\n",
      "  ..., \n",
      "  [  6   4  11]\n",
      "  [  6   2   5]\n",
      "  [  3   3   5]]\n",
      "\n",
      " [[ 10  12  13]\n",
      "  [ 14  12  16]\n",
      "  [ 16  14  15]\n",
      "  ..., \n",
      "  [  2   5  11]\n",
      "  [  1   3   6]\n",
      "  [  6   2   2]]\n",
      "\n",
      " [[ 19  10  18]\n",
      "  [ 11   8  15]\n",
      "  [ 23   9   7]\n",
      "  ..., \n",
      "  [  3   5  10]\n",
      "  [  2   3   5]\n",
      "  [  1   3   5]]]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[[[254 254 254]\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  ..., \n",
      "  [208 205 211]\n",
      "  [207 204 209]\n",
      "  [206 200 204]]\n",
      "\n",
      " [[249 245 249]\n",
      "  [251 250 251]\n",
      "  [250 251 253]\n",
      "  ..., \n",
      "  [202 199 206]\n",
      "  [201 199 206]\n",
      "  [197 195 205]]\n",
      "\n",
      " [[242 239 242]\n",
      "  [242 237 242]\n",
      "  [243 240 243]\n",
      "  ..., \n",
      "  [193 187 202]\n",
      "  [192 192 200]\n",
      "  [190 190 198]]\n",
      "\n",
      " ..., \n",
      " [[106 118 144]\n",
      "  [107 117 146]\n",
      "  [102 123 149]\n",
      "  ..., \n",
      "  [ 35  33  36]\n",
      "  [ 15  20  13]\n",
      "  [ 21  18  21]]\n",
      "\n",
      " [[155 137 157]\n",
      "  [157 137 157]\n",
      "  [152 139 158]\n",
      "  ..., \n",
      "  [ 38  34  38]\n",
      "  [ 13  12  15]\n",
      "  [  6   8  15]]\n",
      "\n",
      " [[112 106 130]\n",
      "  [122 109 127]\n",
      "  [133 109 123]\n",
      "  ..., \n",
      "  [ 42  30  26]\n",
      "  [ 10  15  11]\n",
      "  [  2   5  11]]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  1.]\n",
      "[[[216  30  28]\n",
      "  [181  57  58]\n",
      "  [180  57  56]\n",
      "  ..., \n",
      "  [172  41  45]\n",
      "  [173  44  46]\n",
      "  [195  44  49]]\n",
      "\n",
      " [[196  72  61]\n",
      "  [133 140 122]\n",
      "  [125 131 118]\n",
      "  ..., \n",
      "  [ 69  67  79]\n",
      "  [ 73  63  74]\n",
      "  [111  57  71]]\n",
      "\n",
      " [[219  95  80]\n",
      "  [182 188 158]\n",
      "  [179 185 160]\n",
      "  ..., \n",
      "  [ 76  78  94]\n",
      "  [ 78  77  92]\n",
      "  [123  68  86]]\n",
      "\n",
      " ..., \n",
      " [[214  78  65]\n",
      "  [134 111  94]\n",
      "  [ 78  65  57]\n",
      "  ..., \n",
      "  [103 123 123]\n",
      "  [108 121 120]\n",
      "  [153 114 116]]\n",
      "\n",
      " [[160  22  22]\n",
      "  [ 64  43  43]\n",
      "  [ 56  43  48]\n",
      "  ..., \n",
      "  [107 121 122]\n",
      "  [110 123 121]\n",
      "  [150 113 113]]\n",
      "\n",
      " [[168  13  13]\n",
      "  [ 68  15  16]\n",
      "  [ 64  11  20]\n",
      "  ..., \n",
      "  [151 114 115]\n",
      "  [155 112 113]\n",
      "  [192 108 112]]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.]\n",
      "[[[209 205 241]\n",
      "  [210 195 244]\n",
      "  [197 189 245]\n",
      "  ..., \n",
      "  [105 169 205]\n",
      "  [105 164 205]\n",
      "  [106 167 204]]\n",
      "\n",
      " [[176 157 219]\n",
      "  [168 162 224]\n",
      "  [172 178 226]\n",
      "  ..., \n",
      "  [107 170 212]\n",
      "  [ 98 170 208]\n",
      "  [ 98 169 204]]\n",
      "\n",
      " [[132 123 187]\n",
      "  [127 137 191]\n",
      "  [136 134 189]\n",
      "  ..., \n",
      "  [ 78 160 199]\n",
      "  [ 72 154 196]\n",
      "  [ 80 152 192]]\n",
      "\n",
      " ..., \n",
      " [[159 158 215]\n",
      "  [155 159 212]\n",
      "  [146 154 209]\n",
      "  ..., \n",
      "  [ 44  20   3]\n",
      "  [ 14   4   8]\n",
      "  [  6   4   9]]\n",
      "\n",
      " [[173 166 224]\n",
      "  [171 165 221]\n",
      "  [167 164 218]\n",
      "  ..., \n",
      "  [106 123 129]\n",
      "  [ 54  36  23]\n",
      "  [  9   3   2]]\n",
      "\n",
      " [[175 168 223]\n",
      "  [173 167 221]\n",
      "  [168 165 219]\n",
      "  ..., \n",
      "  [117 131 164]\n",
      "  [100  64 145]\n",
      "  [ 53  21   5]]]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[[[ 89  97  96]\n",
      "  [100 108 107]\n",
      "  [108 114 112]\n",
      "  ..., \n",
      "  [145 147 145]\n",
      "  [141 144 142]\n",
      "  [139 142 139]]\n",
      "\n",
      " [[ 93 101 100]\n",
      "  [101 109 108]\n",
      "  [110 115 114]\n",
      "  ..., \n",
      "  [146 148 147]\n",
      "  [143 146 144]\n",
      "  [141 144 142]]\n",
      "\n",
      " [[ 93 101 100]\n",
      "  [104 112 111]\n",
      "  [110 116 114]\n",
      "  ..., \n",
      "  [146 149 147]\n",
      "  [145 148 146]\n",
      "  [144 147 145]]\n",
      "\n",
      " ..., \n",
      " [[183 175 171]\n",
      "  [194 186 183]\n",
      "  [197 190 184]\n",
      "  ..., \n",
      "  [ 26  15  14]\n",
      "  [ 30  18  16]\n",
      "  [ 34  22  20]]\n",
      "\n",
      " [[190 181 177]\n",
      "  [205 196 192]\n",
      "  [204 196 188]\n",
      "  ..., \n",
      "  [ 22  11  10]\n",
      "  [ 30  18  16]\n",
      "  [ 32  20  18]]\n",
      "\n",
      " [[194 186 178]\n",
      "  [208 201 192]\n",
      "  [208 201 192]\n",
      "  ..., \n",
      "  [ 26  15  14]\n",
      "  [ 28  16  14]\n",
      "  [ 30  18  16]]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[[[181 168 202]\n",
      "  [159 172 202]\n",
      "  [160 171 207]\n",
      "  ..., \n",
      "  [194 204 222]\n",
      "  [192 200 220]\n",
      "  [189 200 220]]\n",
      "\n",
      " [[166 173 202]\n",
      "  [162 172 203]\n",
      "  [163 170 204]\n",
      "  ..., \n",
      "  [226 238 245]\n",
      "  [231 238 244]\n",
      "  [233 239 246]]\n",
      "\n",
      " [[157 170 204]\n",
      "  [150 171 203]\n",
      "  [179 174 204]\n",
      "  ..., \n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  [254 254 254]]\n",
      "\n",
      " ..., \n",
      " [[ 16 152 203]\n",
      "  [ 63 198 204]\n",
      "  [182 121 140]\n",
      "  ..., \n",
      "  [ 78  90 116]\n",
      "  [ 83  90 106]\n",
      "  [ 88  96 102]]\n",
      "\n",
      " [[180 199 250]\n",
      "  [188 170 225]\n",
      "  [189 193 159]\n",
      "  ..., \n",
      "  [ 92  91 120]\n",
      "  [ 90  85 107]\n",
      "  [ 94 104 104]]\n",
      "\n",
      " [[ 48  95 199]\n",
      "  [167 172 215]\n",
      "  [164  79 117]\n",
      "  ..., \n",
      "  [ 75  89 103]\n",
      "  [ 50  77  96]\n",
      "  [ 83  84  96]]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[[[ 47  58  73]\n",
      "  [ 52  61  68]\n",
      "  [ 49  62  75]\n",
      "  ..., \n",
      "  [ 99 209 215]\n",
      "  [157 212 245]\n",
      "  [160 203 245]]\n",
      "\n",
      " [[ 58  62  74]\n",
      "  [ 56  61  71]\n",
      "  [ 60  62  68]\n",
      "  ..., \n",
      "  [ 45  93 111]\n",
      "  [ 93  61 169]\n",
      "  [ 98 172 228]]\n",
      "\n",
      " [[ 47  59  75]\n",
      "  [ 46  60  73]\n",
      "  [ 68  62  73]\n",
      "  ..., \n",
      "  [ 92 103 119]\n",
      "  [ 73  86 122]\n",
      "  [ 94 112 162]]\n",
      "\n",
      " ..., \n",
      " [[141 135 147]\n",
      "  [141 131 151]\n",
      "  [149 135 148]\n",
      "  ..., \n",
      "  [ 80  77  94]\n",
      "  [ 49  58  80]\n",
      "  [ 27  45  61]]\n",
      "\n",
      " [[136  98 139]\n",
      "  [128 101 141]\n",
      "  [116  99 143]\n",
      "  ..., \n",
      "  [ 71  63  87]\n",
      "  [ 67  52  85]\n",
      "  [ 36  53  58]]\n",
      "\n",
      " [[119 127 145]\n",
      "  [119 128 145]\n",
      "  [130 131 147]\n",
      "  ..., \n",
      "  [ 70  79 100]\n",
      "  [ 65  62  93]\n",
      "  [ 29  62  68]]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[[[254 254 254]\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  ..., \n",
      "  [ 49  34  61]\n",
      "  [ 50  35  58]\n",
      "  [ 54  35  61]]\n",
      "\n",
      " [[254 254 253]\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  ..., \n",
      "  [ 52  39  57]\n",
      "  [ 52  37  55]\n",
      "  [ 14  34  58]]\n",
      "\n",
      " [[253 253 253]\n",
      "  [254 254 254]\n",
      "  [254 254 254]\n",
      "  ..., \n",
      "  [ 47  33  55]\n",
      "  [ 48  28  62]\n",
      "  [ 47  25  58]]\n",
      "\n",
      " ..., \n",
      " [[ 70  86 117]\n",
      "  [ 82  87 120]\n",
      "  [ 71  90 124]\n",
      "  ..., \n",
      "  [ 10   9  44]\n",
      "  [ 20   9  44]\n",
      "  [ 14   9  43]]\n",
      "\n",
      " [[ 80  84 114]\n",
      "  [ 77  84 118]\n",
      "  [ 73  88 122]\n",
      "  ..., \n",
      "  [ 38  10  44]\n",
      "  [ 25  10  43]\n",
      "  [  2  10  42]]\n",
      "\n",
      " [[ 82  81 113]\n",
      "  [ 68  83 117]\n",
      "  [ 56  82 121]\n",
      "  ..., \n",
      "  [ 29  16  36]\n",
      "  [ 16  14  42]\n",
      "  [ 11  12  42]]]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n",
      "[[[250 250 251]\n",
      "  [250 250 251]\n",
      "  [251 250 251]\n",
      "  ..., \n",
      "  [166 140 205]\n",
      "  [154 140 206]\n",
      "  [159 104 167]]\n",
      "\n",
      " [[250 250 251]\n",
      "  [250 250 251]\n",
      "  [250 250 251]\n",
      "  ..., \n",
      "  [111 170 191]\n",
      "  [ 95 171 195]\n",
      "  [111 175 177]]\n",
      "\n",
      " [[250 250 251]\n",
      "  [250 250 251]\n",
      "  [250 250 251]\n",
      "  ..., \n",
      "  [100 162 189]\n",
      "  [ 92 163 192]\n",
      "  [ 98 155 171]]\n",
      "\n",
      " ..., \n",
      " [[ 30  20  28]\n",
      "  [ 25  20  28]\n",
      "  [ 36  20  29]\n",
      "  ..., \n",
      "  [ 18  44  31]\n",
      "  [ 20   8  14]\n",
      "  [ 12   9  15]]\n",
      "\n",
      " [[ 34  23  27]\n",
      "  [ 11  22  22]\n",
      "  [ 18  21  23]\n",
      "  ..., \n",
      "  [  8  35  26]\n",
      "  [ 26   8  15]\n",
      "  [  6   9  14]]\n",
      "\n",
      " [[ 19  26  25]\n",
      "  [ 16  22  20]\n",
      "  [ 22  17  17]\n",
      "  ..., \n",
      "  [ 22  26  32]\n",
      "  [ 30   7   6]\n",
      "  [  6   9   8]]]\n"
     ]
    }
   ],
   "source": [
    "#_____ SETTING THE DATA PATH ______\n",
    "DATADIR = \"/Users/ewa_anna_szyszka/Desktop/ImageRecognition/data\"\n",
    "\n",
    "#_____ CATEGORIES OF CLASSES ______\n",
    "CATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\",\"F\", \"G\", \"H\", \"I\", \"J\",\"K\", \"L\", \"M\",'N','O','P','R','S','T','U','W','X','Y','Z']\n",
    "\n",
    "#_____ SETTING UP THE TRAINING DATA ______\n",
    "IMG_SIZE = 50\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        one_hot_target = np.zeros(len(CATEGORIES))\n",
    "        class_num = CATEGORIES.index(category)  #the category encoading\n",
    "        one_hot_target[class_num] = 1\n",
    "        \n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img)) #cv2.IMREAD_GRAYSCALE\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array,one_hot_target])  #[image, category]\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            #plt.imshow(img_array, cmap='gray')\n",
    "            #plt.show()\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "#___ SHUFFLING THE DATA TO IMPROVE THE TRAINING QUALITY _____\n",
    "random.shuffle(training_data)\n",
    "\n",
    "\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])\n",
    "    print(sample[0])\n",
    "\n",
    "\n",
    "X = [] #feature set\n",
    "y = [] #labels\n",
    "\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE, 3) # 1 because it is a gray scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pickle_out = open(\"X.pickle\",'wb')\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out= open(\"y.pickle\",'wb')\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "pickle_in = open(\"X.pickle\",'rb')\n",
    "print('ready')\n",
    "X = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 35,  27,  74],\n",
       "        [ 50,  30,  88],\n",
       "        [ 65,  81, 134],\n",
       "        ..., \n",
       "        [ 16,   8,  49],\n",
       "        [ 25,   6,  48],\n",
       "        [ 21,   9,  42]],\n",
       "\n",
       "       [[ 50,  57, 100],\n",
       "        [ 33,  30,  90],\n",
       "        [ 58,  43, 113],\n",
       "        ..., \n",
       "        [ 23,   7,  48],\n",
       "        [ 22,   9,  45],\n",
       "        [ 20,   8,  45]],\n",
       "\n",
       "       [[ 79,  92, 132],\n",
       "        [ 76,  72, 123],\n",
       "        [ 88,  82, 135],\n",
       "        ..., \n",
       "        [ 24,   8,  50],\n",
       "        [ 22,   9,  45],\n",
       "        [ 22,   9,  42]],\n",
       "\n",
       "       ..., \n",
       "       [[ 23,  13,  18],\n",
       "        [  8,  11,  17],\n",
       "        [ 15,  12,  18],\n",
       "        ..., \n",
       "        [  6,   4,  11],\n",
       "        [  6,   2,   5],\n",
       "        [  3,   3,   5]],\n",
       "\n",
       "       [[ 10,  12,  13],\n",
       "        [ 14,  12,  16],\n",
       "        [ 16,  14,  15],\n",
       "        ..., \n",
       "        [  2,   5,  11],\n",
       "        [  1,   3,   6],\n",
       "        [  6,   2,   2]],\n",
       "\n",
       "       [[ 19,  10,  18],\n",
       "        [ 11,   8,  15],\n",
       "        [ 23,   9,   7],\n",
       "        ..., \n",
       "        [  3,   5,  10],\n",
       "        [  2,   3,   5],\n",
       "        [  1,   3,   5]]], dtype=uint8)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = np.asarray(y)\n",
    "type(y)\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",'rb'))\n",
    "y = pickle.load(open(\"y.pickle\",'rb'))\n",
    "\n",
    "\n",
    "\n",
    "#normalizing the imagery data --> 255 max ---> why and explain \n",
    "X = X/255.0 # normalizing the image data --> expplain why \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68635, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Test train split in the data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45985, 45985, 22650, 22650)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(y_train) ,len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reshapig the data to the correct size \n",
    "\n",
    "X_train = X_train.reshape(45985,50,50,3)\n",
    "X_test = X_test.reshape(22650,50,50,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45985, 45985, 22650, 22650)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(y_train) ,len(X_test),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45985 samples, validate on 22650 samples\n",
      "Epoch 1/3\n",
      "45985/45985 [==============================] - 521s 11ms/step - loss: 0.6773 - acc: 0.8156 - val_loss: 0.3441 - val_acc: 0.9041\n",
      "Epoch 2/3\n",
      "45985/45985 [==============================] - 477s 10ms/step - loss: 0.1977 - acc: 0.9448 - val_loss: 0.3002 - val_acc: 0.9203\n",
      "Epoch 3/3\n",
      "45985/45985 [==============================] - 424s 9ms/step - loss: 0.0920 - acc: 0.9744 - val_loss: 0.3107 - val_acc: 0.9225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb4cb7f690>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten#create model\n",
    "model = Sequential()#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(50,50,3)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(24, activation=\"softmax\"))\n",
    "#\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#using first 4 test data points to check the model\n",
    "first_predictions = model.predict(X_test[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.26876536e-15   5.03923570e-10   4.73471574e-11   9.99999523e-01\n",
      "   3.08350004e-12   3.44905828e-08   1.06987037e-10   2.40832202e-12\n",
      "   1.30400934e-07   2.77398542e-17   4.90254637e-09   9.44884260e-09\n",
      "   1.61159792e-14   6.25753572e-13   2.87943058e-10   8.34928071e-10\n",
      "   6.34221635e-08   1.37108117e-10   4.01560873e-09   8.40325232e-09\n",
      "   9.57058434e-13   2.50951501e-07   1.69069619e-11   4.27788489e-18]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.81960784,  0.89019608,  0.86666667],\n",
       "        [ 0.76470588,  0.87058824,  0.88627451],\n",
       "        [ 0.72941176,  0.8627451 ,  0.88627451],\n",
       "        ..., \n",
       "        [ 0.34509804,  0.31372549,  0.50588235],\n",
       "        [ 0.38823529,  0.25882353,  0.30196078],\n",
       "        [ 0.25882353,  0.21568627,  0.30588235]],\n",
       "\n",
       "       [[ 0.82745098,  0.99215686,  0.98431373],\n",
       "        [ 0.86666667,  0.99215686,  0.98823529],\n",
       "        [ 0.83529412,  0.98823529,  0.99215686],\n",
       "        ..., \n",
       "        [ 0.28627451,  0.25882353,  0.51372549],\n",
       "        [ 0.36862745,  0.30980392,  0.31764706],\n",
       "        [ 0.27058824,  0.19607843,  0.30980392]],\n",
       "\n",
       "       [[ 0.9372549 ,  0.98039216,  0.99215686],\n",
       "        [ 0.94509804,  0.98039216,  0.99215686],\n",
       "        [ 0.94117647,  0.95686275,  0.97254902],\n",
       "        ..., \n",
       "        [ 0.30196078,  0.29019608,  0.53333333],\n",
       "        [ 0.37254902,  0.16470588,  0.30980392],\n",
       "        [ 0.23921569,  0.19215686,  0.30980392]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.71372549,  0.75294118,  0.92156863],\n",
       "        [ 0.69411765,  0.76078431,  0.90196078],\n",
       "        [ 0.73333333,  0.74117647,  0.90588235],\n",
       "        ..., \n",
       "        [ 0.08627451,  0.04313725,  0.0627451 ],\n",
       "        [ 0.11764706,  0.12941176,  0.24705882],\n",
       "        [ 0.15294118,  0.21176471,  0.29803922]],\n",
       "\n",
       "       [[ 0.71764706,  0.76470588,  0.90196078],\n",
       "        [ 0.71372549,  0.71764706,  0.89019608],\n",
       "        [ 0.74509804,  0.75294118,  0.89803922],\n",
       "        ..., \n",
       "        [ 0.12941176,  0.11764706,  0.19215686],\n",
       "        [ 0.22745098,  0.23137255,  0.2745098 ],\n",
       "        [ 0.21176471,  0.32941176,  0.30196078]],\n",
       "\n",
       "       [[ 0.62352941,  0.72941176,  0.89411765],\n",
       "        [ 0.63921569,  0.72156863,  0.88235294],\n",
       "        [ 0.63137255,  0.72156863,  0.90588235],\n",
       "        ..., \n",
       "        [ 0.14509804,  0.15294118,  0.18823529],\n",
       "        [ 0.12941176,  0.23529412,  0.25098039],\n",
       "        [ 0.16078431,  0.20392157,  0.28627451]]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted \n",
    "print(first_predictions[0])\n",
    "print(y_test[0])\n",
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb4c52e690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "a = X_test[3]\n",
    "img = Image.fromarray(a,'RGB')\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img, interpolation='nearest')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "#img = Image.fromarray(first_predictions[0], 'RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ..., \n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ..., \n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "w, h = 512, 512\n",
    "data = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "data[256, 256] = [255, 0, 0]\n",
    "print(data)\n",
    "img = Image.fromarray(data, 'RGB')\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((45985, 50, 50, 3), (22650, 50, 50, 3))\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MaxPooling2D' object has no attribute 'outbound_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-b70126a19d5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#x = Flatten()(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m45985\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# First: train only the top layers (which were randomly initialized)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \"\"\"\n\u001b[1;32m    257\u001b[0m     \u001b[0;31m# Actually call the layer (optionally building it).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_eager_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;31m# This updates the layer history of the output tensor(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m         self._add_inbound_node(\n\u001b[0;32m--> 768\u001b[0;31m             input_tensors=inputs, output_tensors=outputs, arguments=user_kwargs)\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.pyc\u001b[0m in \u001b[0;36m_add_inbound_node\u001b[0;34m(self, input_tensors, output_tensors, arguments)\u001b[0m\n\u001b[1;32m    843\u001b[0m         \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m         arguments=arguments)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;31m# Update tensor history metadata.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/layers/base.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, arguments)\u001b[0m\n\u001b[1;32m   1368\u001b[0m         \u001b[0;31m# For compatibility with external Keras, we use the deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# accessor here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;31m# For compatibility with external Keras, we use the deprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;31m# accessor here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MaxPooling2D' object has no attribute 'outbound_nodes'"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "import keras\n",
    "base_model = VGG19(#weights='imagenet',\n",
    "    weights = None, include_top=False, input_shape=(50,50, 3))\n",
    "x = base_model.output\n",
    "#x = Flatten()(x)\n",
    "predictions = Dense(45985, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "# First: train only the top layers (which were randomly initialized)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "callbacks_list = [keras.callbacks.EarlyStopping(monitor='val_acc', patience=3, verbose=1)]\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 45985 arrays: [array([[ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n   ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-25eb8e055a2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 45985 arrays: [array([[ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n   ..."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_5_input to have 2 dimensions, but got array with shape (45985, 50, 50, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-34223b669c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1682\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1508\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m   1509\u001b[0m     y = _standardize_input_data(\n\u001b[1;32m   1510\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_5_input to have 2 dimensions, but got array with shape (45985, 50, 50, 3)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#The first layer in your model must specify the shape of the input.\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 45985 arrays: [array([[ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 1.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n   ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-b9ab5f7bbea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#X_out = np.concatenate([X_test, y_test])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#model.fit([X_train, X_train], X_out, epochs=50, batch_size=32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 45985 arrays: [array([[ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 1.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n       [ 0.],\n   ..."
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten#create model\n",
    "model = Sequential()#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(50,50,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n",
    "#X_out = np.concatenate([X_test, y_test])\n",
    "#model.fit([X_train, X_train], X_out, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected max_pooling2d_7 to have 4 dimensions, but got array with shape (68635, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-656b28a1dce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1682\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         exception_prefix='target')\n\u001b[0m\u001b[1;32m   1515\u001b[0m     sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1516\u001b[0m                                                  self._feed_output_names)\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected max_pooling2d_7 to have 4 dimensions, but got array with shape (68635, 1)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,(3,3),input_shape = X.shape[1:]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Dense(32, input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam',metrics= ['accuracy'])\n",
    "model.fit(X,y, batch_size=20, validation_split=0.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
