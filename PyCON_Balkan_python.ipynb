{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model imports \n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "\n",
    "#Data procesing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "#Visualization \n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[[250 250 251 ...,  81  74  72]\n",
      " [250 250 250 ...,  31  21  21]\n",
      " [250 250 250 ...,  54  52  52]\n",
      " ..., \n",
      " [  3   6  15 ...,  43  40  40]\n",
      " [  8  13  15 ...,  37  40  39]\n",
      " [ 17  18  21 ...,  37  36  37]]\n",
      "0\n",
      "[[249 249 249 ...,  45  44  44]\n",
      " [250 249 249 ...,  41  48  46]\n",
      " [247 250 249 ...,  53  57  53]\n",
      " ..., \n",
      " [112 106 136 ...,  50  37  32]\n",
      " [118 130 196 ...,  52  37  35]\n",
      " [120 167 206 ...,  83  39  35]]\n",
      "8\n",
      "[[ 24  19  19 ...,  24  36  42]\n",
      " [ 22  11  11 ...,  45  51  47]\n",
      " [ 28  31  24 ...,  53  49  48]\n",
      " ..., \n",
      " [ 84 138 139 ..., 216 220 221]\n",
      " [ 82 139 140 ..., 219 221 222]\n",
      " [ 85 139 139 ..., 220 222 226]]\n",
      "5\n",
      "[[250 250 250 ...,  66  53  58]\n",
      " [250 250 250 ...,  46  57  57]\n",
      " [250 250 250 ...,  51  53  56]\n",
      " ..., \n",
      " [ 56  58  59 ...,   5  17  35]\n",
      " [ 53  58  61 ...,  20  88  77]\n",
      " [ 59  62  56 ...,  43  42  33]]\n",
      "13\n",
      "[[220 231 234 ..., 254 254 254]\n",
      " [253 253 252 ..., 254 254 254]\n",
      " [251 243 232 ..., 254 254 254]\n",
      " ..., \n",
      " [138 133 141 ...,   6  10  19]\n",
      " [138 133 142 ...,  17  11  13]\n",
      " [139 136 145 ...,  28  13   8]]\n",
      "5\n",
      "[[245 251 249 ..., 124 139  81]\n",
      " [232 252 249 ...,  81 142 105]\n",
      " [237 251 249 ...,  40  61  74]\n",
      " ..., \n",
      " [ 18  21  15 ...,  99  94  92]\n",
      " [ 17  19  16 ..., 103  96  94]\n",
      " [ 15  20  15 ..., 118  99  94]]\n",
      "5\n",
      "[[234 235 238 ..., 253 253 253]\n",
      " [ 62  58  56 ..., 253 253 253]\n",
      " [ 93  95  94 ..., 253 253 253]\n",
      " ..., \n",
      " [ 52  52  56 ...,  70  79  95]\n",
      " [ 55  55  59 ...,  68  66  83]\n",
      " [ 63  61  63 ...,  71  61  64]]\n",
      "14\n",
      "[[ 70  71  73 ..., 205 198 196]\n",
      " [ 74  76  75 ..., 110 108 106]\n",
      " [ 73  73  74 ..., 110 103  65]\n",
      " ..., \n",
      " [137 137 136 ..., 108 111 113]\n",
      " [137 136 139 ..., 114 114 115]\n",
      " [138 137 140 ..., 116 117 115]]\n",
      "19\n",
      "[[ 55  70 103 ..., 251 251 251]\n",
      " [ 45  49  74 ..., 251 251 251]\n",
      " [ 60  76  92 ..., 251 251 251]\n",
      " ..., \n",
      " [191 189 187 ..., 109  66  27]\n",
      " [192 193 193 ..., 130 121  80]\n",
      " [194 194 196 ..., 119 124 137]]\n",
      "3\n",
      "[[251 251 251 ...,  54  53  52]\n",
      " [250 251 251 ...,  52  51  51]\n",
      " [250 250 250 ...,  48  51  49]\n",
      " ..., \n",
      " [ 17  13   8 ..., 147 105 110]\n",
      " [ 22  15   8 ..., 145 144 143]\n",
      " [ 20  16   7 ..., 117 142 143]]\n"
     ]
    }
   ],
   "source": [
    "#_____ SETTING THE DATA PATH ______\n",
    "DATADIR = \"/Users/ewa_anna_szyszka/Desktop/ImageRecognition/data\"\n",
    "\n",
    "#_____ CATEGORIES OF CLASSES ______\n",
    "CATEGORIES = [\"A\", \"B\", \"C\", \"D\", \"E\",\"F\", \"G\", \"H\", \"I\", \"J\",\"K\", \"L\", \"M\",'N','O','P','R','S','T','U','W','X','Y','Z']\n",
    "\n",
    "#_____ SETTING UP THE TRAINING DATA ______\n",
    "IMG_SIZE = 50\n",
    "\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category)\n",
    "        class_num = CATEGORIES.index(category)  #the category encoading\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array,class_num])  #[image, category]\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            #plt.imshow(img_array, cmap='gray')\n",
    "            #plt.show()\n",
    "\n",
    "create_training_data()\n",
    "\n",
    "#___ SHUFFLING THE DATA TO IMPROVE THE TRAINING QUALITY _____\n",
    "random.shuffle(training_data)\n",
    "\n",
    "\n",
    "for sample in training_data[:10]:\n",
    "    print(sample[1])\n",
    "    print(sample[0])\n",
    "\n",
    "\n",
    "X = [] #feature set\n",
    "y = [] #labels\n",
    "\n",
    "\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE, 1) # 1 because it is a gray scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pickle_out = open(\"X.pickle\",'wb')\n",
    "pickle.dump(X,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out= open(\"y.pickle\",'wb')\n",
    "pickle.dump(y,pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "\n",
    "pickle_in = open(\"X.pickle\",'rb')\n",
    "print('ready')\n",
    "X = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[249],\n",
       "        [249],\n",
       "        [249],\n",
       "        ..., \n",
       "        [ 45],\n",
       "        [ 44],\n",
       "        [ 44]],\n",
       "\n",
       "       [[250],\n",
       "        [249],\n",
       "        [249],\n",
       "        ..., \n",
       "        [ 41],\n",
       "        [ 48],\n",
       "        [ 46]],\n",
       "\n",
       "       [[247],\n",
       "        [250],\n",
       "        [249],\n",
       "        ..., \n",
       "        [ 53],\n",
       "        [ 57],\n",
       "        [ 53]],\n",
       "\n",
       "       ..., \n",
       "       [[112],\n",
       "        [106],\n",
       "        [136],\n",
       "        ..., \n",
       "        [ 50],\n",
       "        [ 37],\n",
       "        [ 32]],\n",
       "\n",
       "       [[118],\n",
       "        [130],\n",
       "        [196],\n",
       "        ..., \n",
       "        [ 52],\n",
       "        [ 37],\n",
       "        [ 35]],\n",
       "\n",
       "       [[120],\n",
       "        [167],\n",
       "        [206],\n",
       "        ..., \n",
       "        [ 83],\n",
       "        [ 39],\n",
       "        [ 35]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X = pickle.load(open(\"X.pickle\",'rb'))\n",
    "y = pickle.load(open(\"y.pickle\",'rb'))\n",
    "\n",
    "\n",
    "\n",
    "#normalizing the imagery data --> 255 max ---> why and explain \n",
    "X = X/255.0 # normalizing the image data --> expplain why \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68635, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Test train split in the data \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45985, 45985, 22650, 22650)\n",
      "(45985, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train),len(y_train) ,len(X_test),len(y_test))\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#reshapig the data to the correct size \n",
    "\n",
    "X_train = X_train.reshape(45985,50,50,1)\n",
    "X_test = X_test.reshape(22650,50,50,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#___1hotncoding____\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected max_pooling2d_7 to have 4 dimensions, but got array with shape (68635, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-656b28a1dce1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1682\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1512\u001b[0m         \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         exception_prefix='target')\n\u001b[0m\u001b[1;32m   1515\u001b[0m     sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1516\u001b[0m                                                  self._feed_output_names)\n",
      "\u001b[0;32m/Users/ewa_anna_szyszka/anaconda/lib/python2.7/site-packages/tensorflow/python/keras/_impl/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected max_pooling2d_7 to have 4 dimensions, but got array with shape (68635, 1)"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64,(3,3),input_shape = X.shape[1:]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Dense(32, input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam',metrics= ['accuracy'])\n",
    "model.fit(X,y, batch_size=20, validation_split=0.1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ewa_anna_szyszka\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
